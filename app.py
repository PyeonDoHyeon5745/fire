import streamlit as st
import pandas as pd
import folium
import requests
from streamlit_folium import st_folium
import openai
import math
import os


# âœ… GPT í´ë¼ì´ì–¸íŠ¸ ìƒì„± (OpenAI v1.x ì´ìƒ ê¸°ì¤€)
openai.api_key = st.secrets["OPENAI_API_KEY"]

# âœ… ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”ëŠ” GPT í˜¸ì¶œë³´ë‹¤ ìœ„ì— ìˆì–´ì•¼ í•¨
if "firechat" not in st.session_state:
    st.session_state.firechat = [
        {"role": "system", "content": "ë‹¹ì‹ ì€ í™”ì¬ ì¬ë°œ ë°©ì§€ì™€ ì•ˆì „ì— ëŒ€í•œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì¹œì ˆí•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”."}
    ]


##############################  ğŸ–¥ï¸ í˜ì´ì§€ ì„¤ì • ##############################


# ğŸ–¥ï¸ í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ì¬í™”ì¬ ì˜ˆì¸¡ ë¶„ì„ ì‹œìŠ¤í…œ", layout="wide", page_icon="âš ï¸")

# ğŸ¨ ìŠ¤íƒ€ì¼ ì •ì˜
st.markdown("""
<style>
    .metric-container {
        display: flex;
        justify-content: space-around;
        margin-top: 2rem;
    }

    .metric-box {
        flex: 1;
        margin: 0 1rem;
        padding: 2rem;
        background: #f4f6fa;
        border-radius: 16px;
        box-shadow: 0 4px 20px rgba(0, 0, 0, 0.08);
        text-align: center;
        transition: transform 0.3s ease;
    }

    .metric-box:hover {
        transform: translateY(-5px);
    }

    .metric-title {
        font-size: 1.1rem;
        font-weight: 600;
        color: #333;
        margin-bottom: 1rem;
    }

    .metric-value {
        font-size: 2.8rem;
        font-weight: bold;
        background: linear-gradient(135deg, #667eea, #764ba2);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
    }
</style>
""", unsafe_allow_html=True)

# ğŸ”¥ ì œëª©
st.markdown("""
<div style="text-align: center; padding-top: 2rem;">
    <h1 style="font-size: 2.8rem;"> ğŸ”¥ ì¬í™”ì¬ ì˜ˆì¸¡ ë¶„ì„ ì‹œìŠ¤í…œ ğŸ”¥</h1>
    <p style="font-size: 1.2rem; color: gray;">ì¢…í•©ë¦¬í¬íŠ¸</p>
</div>
""", unsafe_allow_html=True)

# âœ… ë°•ìŠ¤ 4ê°œ (ë”ë¯¸ ê°’)
num_sources = 128
num_detections = 64
num_types = 5
success_rate = 87.5

st.markdown(f"""
<div class="metric-container">
    <div class="metric-box">
        <div class="metric-title">ğŸ­ ì´ ê±´ë¬¼ ìˆ˜</div>
        <div class="metric-value">{num_sources}ê°œ</div>
    </div>
    <div class="metric-box">
        <div class="metric-title">âš ï¸ ê³ ìœ„í—˜ ê±´ë¬¼ ì˜ˆì¸¡ ìˆ˜</div>
        <div class="metric-value">{num_detections}ê±´</div>
    </div>
    <div class="metric-box">
        <div class="metric-title">ğŸ“Š ì˜¤ëŠ˜ì˜ ë‚ ì”¨</div>
        <div class="metric-value">{num_types}ì¢…</div>
    </div>
    <div class="metric-box">
        <div class="metric-title">ğŸ“ˆ ë¶„ì„ ì„±ê³µë¥ </div>
        <div class="metric-value">{success_rate:.1f}%</div>
    </div>
</div>
""", unsafe_allow_html=True)

############################## GPT ì¸í„°í˜ì´ìŠ¤ ##############################
# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = openai.OpenAI(api_key=st.secrets["OPENAI_API_KEY"])


st.markdown("---")
st.subheader("ğŸ§  GPT ê¸°ë°˜ í™”ì¬ ê´€ë ¨ ì§ˆë¬¸ ìƒë‹´")

# ì´ì „ ëŒ€í™” ì¶œë ¥
for msg in st.session_state.firechat[1:]:
    if msg["role"] == "user":
        st.markdown(f"<div style='text-align:right; background-color:#dcf8c6; padding:8px; border-radius:10px; margin:5px 0;'>{msg['content']}</div>", unsafe_allow_html=True)
    elif msg["role"] == "assistant":
        st.markdown(f"<div style='text-align:left; background-color:#fff; padding:8px; border-radius:10px; margin:5px 0;'>{msg['content']}</div>", unsafe_allow_html=True)

# ì…ë ¥ í¼
with st.form("firechat_form", clear_on_submit=True):
    user_input = st.text_input("ğŸ”¥ í™”ì¬ ê´€ë ¨ ê¶ê¸ˆí•œ ì ì„ ì…ë ¥í•´ ë³´ì„¸ìš”!")
    submitted = st.form_submit_button("ë³´ë‚´ê¸°")

# GPT ì‘ë‹µ ì²˜ë¦¬
if submitted and user_input:
    st.session_state.firechat.append({"role": "user", "content": user_input})

    with st.spinner("GPTê°€ ë‹µë³€ì„ ì‘ì„± ì¤‘ì…ë‹ˆë‹¤..."):
        reply = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=st.session_state.firechat
        ).choices[0].message.content

    st.session_state.firechat.append({"role": "assistant", "content": reply})
    st.rerun()
